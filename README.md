# MSCS_634_Lab_5

## Purpose of the lab work

The purpose of this lab was to gain hands-on experience with two major unsupervised learning methods. They are Hierarchical Clustering and DBSCAN which we are applying with the standardized Wine dataset. Through the step-by-step process, the lab aims to help us understand how clustering algorithms behave on real data, how parameter choices affect outcomes, and how to interpret clustering structures both numerically and visually. By preparing and exploring the dataset, applying different clustering techniques, tuning parameters, and evaluating results using metrics such as silhouette, homogeneity, and completeness scores, the lab provided a practical foundation for understanding how unsupervised learning can reveal patterns in complex datasets.

## Key Insights From Your Clustering Results and Visualizations
The clustering results and visualizations revealed clear differences in how Hierarchical Clustering and DBSCAN interpret the structure of the Wine dataset. Hierarchical clustering produced stable and predictable cluster assignments across different values of n_clusters, with moderately positive silhouette scores that suggested some underlying separation in the data, though not extremely strong. The dendrogram further highlighted how certain groups merged gradually, showing a fairly balanced hierarchical structure. In contrast, DBSCAN results varied widely depending on eps and min_samples, with small eps values leading to no clusters and medium values generating a mix of small dense clusters and many noise points. Visual plots for DBSCAN made these effects clear, especially where noise points scattered around well-defined clusters. These observations emphasized how sensitive DBSCAN is to parameter tuning and how visual analysis is essential for understanding when clusters are meaningful or artificially formed.

## Any challenges faced or decisions made during the lab. 

During this clustering analysis project, I ran into several challenges that required a lot of problem-solving and trial and error. One of the first issues involved the dendrogram visualization where the sample index labels were overlapping because there were too many data points. I fixed this by adjusting the font size and using truncation modes so the diagram became readable. A bigger technical problem came up when I tried to visualize multiple DBSCAN parameter combinations. Ioriginally created a fixed 2x2 subplot layout, but when I mistakely attempted to display seven parameter combinations, I got an IndexError because there were not enough subplots. I solved this by dynamically calculating the number of rows and columns needed based on how many plots I wanted to display and then handling any unused subplots properly. The hardest challenge, however, was tuning the DBSCAN parameters. Many eps and min_samples combinations produced either zero clusters, where all points were noise, or just one huge cluster. Finding meaningful clusters required me to experiment with a wide range of eps values from 1.0 to 3.0 and min_samples values from 3 to 7, and I had to carefully check the evaluation metrics to identify useful configurations. I also had to handle cases where metrics like the silhouette score could not be computed because no real clusters formed, which meant adding conditional checks to avoid errors. Overall, these challenges taught me the importance of writing flexible visualization code, handling edge cases, and taking an iterative approach when tuning parameters in unsupervised learning.
